{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13617982,"sourceType":"datasetVersion","datasetId":8059804}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Menyembunyikan pesan INFO/WARNING\nimport tensorflow as tf\ntf.get_logger().setLevel('ERROR')  # Menyembunyikan log TensorFlow\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import MeanSquaredError\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom tqdm import tqdm\nfrom multiprocessing import Pool\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.metrics import Metric\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport keras\nfrom tensorflow.keras import backend as K\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T06:41:18.942036Z","iopub.execute_input":"2025-12-09T06:41:18.942600Z","iopub.status.idle":"2025-12-09T06:41:22.680339Z","shell.execute_reply.started":"2025-12-09T06:41:18.942574Z","shell.execute_reply":"2025-12-09T06:41:22.679765Z"}},"outputs":[{"name":"stderr","text":"2025-12-09 06:41:19.230663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765262479.252445     231 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765262479.259088     231 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**ATTENTION UNET MODEL**","metadata":{}},{"cell_type":"code","source":"class F1Score(tf.keras.metrics.Metric):\n    \"\"\"Custom F1 Score metric\"\"\"\n    def __init__(self, name='f1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n    \n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.precision.update_state(y_true, y_pred, sample_weight)\n        self.recall.update_state(y_true, y_pred, sample_weight)\n    \n    def result(self):\n        p = self.precision.result()\n        r = self.recall.result()\n        return 2 * ((p * r) / (p + r + K.epsilon()))\n    \n    def reset_state(self):\n        self.precision.reset_state()\n        self.recall.reset_state()\n\ndef attention_gate(gate_signal, skip_connection, inter_channels):\n    \"\"\"\n    Attention Gate untuk memfokuskan pada region yang relevan\n    \n    Args:\n        gate_signal: Input dari decoder (gating signal)\n        skip_connection: Input dari encoder (skip connection)\n        inter_channels: Jumlah channel intermediate\n    \"\"\"\n    # Theta pathway - dari skip connection\n    theta_x = layers.Conv2D(inter_channels, (1, 1), strides=(1, 1), padding='same', use_bias=False)(skip_connection)\n    \n    # Phi pathway - dari gating signal\n    phi_g = layers.Conv2D(inter_channels, (1, 1), strides=(1, 1), padding='same', use_bias=False)(gate_signal)\n    \n    # Upsample phi_g jika ukurannya berbeda dengan theta_x\n    phi_g_upsampled = layers.UpSampling2D(size=(skip_connection.shape[1] // gate_signal.shape[1], \n                                               skip_connection.shape[2] // gate_signal.shape[2]))(phi_g)\n    \n    # Add dan apply ReLU\n    concat_xg = layers.add([theta_x, phi_g_upsampled])\n    act_xg = layers.Activation('relu')(concat_xg)\n    \n    # Psi pathway - menghasilkan attention coefficients\n    psi = layers.Conv2D(1, (1, 1), padding='same', use_bias=True)(act_xg)\n    sigmoid_xg = layers.Activation('sigmoid')(psi)\n    \n    # Upsample attention coefficients untuk matching dimensi\n    upsample_psi = layers.UpSampling2D(size=(1, 1))(sigmoid_xg)\n    \n    # Apply attention coefficients ke skip connection\n    y = layers.multiply([skip_connection, upsample_psi])\n    \n    # Optional: output gate untuk regularisasi\n    result = layers.Conv2D(skip_connection.shape[-1], (1, 1), padding='same')(y)\n    result = layers.BatchNormalization()(result)\n    \n    return result\n\ndef attention_unet_model(input_size=(256, 256, 1)):\n    \"\"\"\n    Attention U-Net model untuk deteksi titik api\n    Dikembangkan dari model U-Net yang sudah ada dengan penambahan attention gates\n    \"\"\"\n    inputs = tf.keras.Input(input_size)\n    \n    # Encoder (sama seperti U-Net original dengan sedikit modifikasi)\n    # Block 1\n    c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n    c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n    c1 = layers.BatchNormalization()(c1)  # Tambah BatchNorm untuk stabilitas\n    p1 = layers.MaxPooling2D((2, 2))(c1)\n    p1 = layers.Dropout(0.1)(p1)\n    \n    # Block 2\n    c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n    c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n    c2 = layers.BatchNormalization()(c2)\n    p2 = layers.MaxPooling2D((2, 2))(c2)\n    p2 = layers.Dropout(0.1)(p2)\n    \n    # Block 3\n    c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n    c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c3)\n    c3 = layers.BatchNormalization()(c3)\n    p3 = layers.MaxPooling2D((2, 2))(c3)\n    p3 = layers.Dropout(0.2)(p3)\n    \n    # Bottleneck\n    bn = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n    bn = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn)\n    bn = layers.BatchNormalization()(bn)\n    bn = layers.Dropout(0.3)(bn)\n    \n    # Decoder with Attention Gates\n    # Upsampling Block 1 dengan Attention Gate\n    u1 = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(bn)\n    # Attention gate antara u1 (gating) dan c3 (skip connection)\n    att1 = attention_gate(gate_signal=u1, skip_connection=c3, inter_channels=32)\n    u1 = layers.concatenate([u1, att1])  # Gunakan attended features\n    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n    c4 = layers.BatchNormalization()(c4)\n    c4 = layers.Dropout(0.2)(c4)\n    \n    # Upsampling Block 2 dengan Attention Gate  \n    u2 = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(c4)\n    # Attention gate antara u2 (gating) dan c2 (skip connection)\n    att2 = attention_gate(gate_signal=u2, skip_connection=c2, inter_channels=16)\n    u2 = layers.concatenate([u2, att2])  # Gunakan attended features\n    c5 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u2)\n    c5 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c5)\n    c5 = layers.BatchNormalization()(c5)\n    c5 = layers.Dropout(0.1)(c5)\n    \n    # Upsampling Block 3 dengan Attention Gate\n    u3 = layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same')(c5)\n    # Attention gate antara u3 (gating) dan c1 (skip connection)\n    att3 = attention_gate(gate_signal=u3, skip_connection=c1, inter_channels=8)\n    u3 = layers.concatenate([u3, att3])  # Gunakan attended features\n    c6 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u3)\n    c6 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c6)\n    c6 = layers.BatchNormalization()(c6)\n    c6 = layers.Dropout(0.1)(c6)\n    \n    # Output layer\n    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c6)\n    \n    model = tf.keras.Model(inputs, outputs, name='Attention_UNet')\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T06:41:22.681687Z","iopub.execute_input":"2025-12-09T06:41:22.682230Z","iopub.status.idle":"2025-12-09T06:41:22.699750Z","shell.execute_reply.started":"2025-12-09T06:41:22.682202Z","shell.execute_reply":"2025-12-09T06:41:22.698968Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**UNET MODEL**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, backend as K\n\n# ======= METRIK KUSTOM (tetap) =======\n@tf.keras.utils.register_keras_serializable()\nclass F1Score(tf.keras.metrics.Metric):\n    \"\"\"Custom F1 Score metric\"\"\"\n    def __init__(self, name='f1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n    \n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.precision.update_state(y_true, y_pred, sample_weight)\n        self.recall.update_state(y_true, y_pred, sample_weight)\n    \n    def result(self):\n        p = self.precision.result()\n        r = self.recall.result()\n        return 2 * ((p * r) / (p + r + K.epsilon()))\n    \n    def reset_state(self):\n        self.precision.reset_state()\n        self.recall.reset_state()\n\n# ======= U-NET TANPA ATTENTION =======\ndef unet_model(input_size=(256, 256, 1)):\n    \"\"\"\n    Plain U-Net (tanpa attention gate).\n    Encoder/decoder mengikuti konfigurasi model sebelumnya (16-32-64-128).\n    \"\"\"\n    inputs = tf.keras.Input(input_size)\n\n    # ----- Encoder -----\n    # Block 1\n    c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n    c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n    c1 = layers.BatchNormalization()(c1)\n    p1 = layers.MaxPooling2D((2, 2))(c1)\n    p1 = layers.Dropout(0.1)(p1)\n\n    # Block 2\n    c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n    c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n    c2 = layers.BatchNormalization()(c2)\n    p2 = layers.MaxPooling2D((2, 2))(c2)\n    p2 = layers.Dropout(0.1)(p2)\n\n    # Block 3\n    c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n    c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c3)\n    c3 = layers.BatchNormalization()(c3)\n    p3 = layers.MaxPooling2D((2, 2))(c3)\n    p3 = layers.Dropout(0.2)(p3)\n\n    # ----- Bottleneck -----\n    bn = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n    bn = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn)\n    bn = layers.BatchNormalization()(bn)\n    bn = layers.Dropout(0.3)(bn)\n\n    # ----- Decoder (tanpa attention, langsung concat) -----\n    # Up 1\n    u1 = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(bn)\n    u1 = layers.Concatenate()([u1, c3])\n    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n    c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n    c4 = layers.BatchNormalization()(c4)\n    c4 = layers.Dropout(0.2)(c4)\n\n    # Up 2\n    u2 = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(c4)\n    u2 = layers.Concatenate()([u2, c2])\n    c5 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u2)\n    c5 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c5)\n    c5 = layers.BatchNormalization()(c5)\n    c5 = layers.Dropout(0.1)(c5)\n\n    # Up 3\n    u3 = layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same')(c5)\n    u3 = layers.Concatenate()([u3, c1])\n    c6 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u3)\n    c6 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c6)\n    c6 = layers.BatchNormalization()(c6)\n    c6 = layers.Dropout(0.1)(c6)\n\n    # Output\n    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c6)\n\n    model = tf.keras.Model(inputs, outputs, name='UNet')\n    return model\n\n# ---- contoh pemakaian (opsional) ----\n# model = unet_model(input_size=(256, 256, 1))\n# model.compile(optimizer='adam',\n#               loss='binary_crossentropy',\n#               metrics=[F1Score(name='f1'), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n# model.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LOAD DATA","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\n\n# =========================\n# Lokasi berkas (sesuaikan)\n# =========================\nPATH_TRAIN = \"/kaggle/input/datadeteksikebakaran/datasetIR(7)_train.npz\"\nPATH_VAL   = \"/kaggle/input/datadeteksikebakaran/datasetIR(7)_val.npz\"\n\n# =========================\n# Util memuat 1 split\n# =========================\ndef load_split(npz_path):\n    \"\"\"\n    Memuat split dari .npz berisi:\n      - input_np: (N, H, W, C)\n      - target_np: (N, H, W) atau (N, H, W, K)\n      - file_names: (N,)\n    Mengembalikan (X, y, names) sebagai numpy arrays.\n    \"\"\"\n    if not os.path.isfile(npz_path):\n        raise FileNotFoundError(f\"File tidak ditemukan: {npz_path}\")\n\n    with np.load(npz_path, allow_pickle=True) as d:\n        X = d[\"input_np\"]\n        y = d[\"target_np\"]\n        names = d[\"file_names\"]\n\n    # Pastikan tipe float32 untuk kompatibilitas model\n    if not isinstance(X, np.ndarray):\n        X = np.array(X)\n    if not isinstance(y, np.ndarray):\n        y = np.array(y)\n    X = X.astype(np.float32)\n    y = y.astype(np.float32)\n\n    # Jaga bentuk channel-last (kalau input 3D -> tambahkan channel tunggal)\n    if X.ndim == 3:\n        X = X[..., None]  # (N, H, W) -> (N, H, W, 1)\n\n    # Jika target perlu channel dim (tergantung arsitektur model), contoh:\n    # if y.ndim == 3 and NEEDS_CHANNEL:\n    #     y = y[..., None]\n\n    # Konversi file_names ke list of str\n    try:\n        names = names.tolist()\n    except Exception:\n        names = list(names)\n    names = [str(n) for n in names]\n\n    return X, y, names\n\n# =========================\n# Muat train & val\n# =========================\nX_train, y_train, names_train = load_split(PATH_TRAIN)\nX_val,   y_val,   names_val   = load_split(PATH_VAL)\n\nprint(\"Train:\", X_train.shape, y_train.shape, \"N files:\", len(names_train))\nprint(\"Val  :\", X_val.shape,   y_val.shape,   \"N files:\", len(names_val))\n\n# =========================\n# tf.data pipeline\n# =========================\nAUTOTUNE   = tf.data.AUTOTUNE\nBATCH_SIZE = 8  # sesuaikan dengan GPU/memori\n\ndef make_dataset(X, y, batch_size=BATCH_SIZE, training=True):\n    ds = tf.data.Dataset.from_tensor_slices((X, y))\n    if training:\n        ds = ds.shuffle(buffer_size=len(X), reshuffle_each_iteration=True)\n    ds = ds.batch(batch_size, drop_remainder=False)\n    ds = ds.prefetch(AUTOTUNE)\n    return ds\n\nds_train = make_dataset(X_train, y_train, training=True)\nds_val   = make_dataset(X_val,   y_val,   training=False)\n\nprint(\"Contoh nama file train[0]:\", names_train[0] if len(names_train) else \"(kosong)\")\nprint(\"Contoh nama file val[0]  :\", names_val[0]   if len(names_val)   else \"(kosong)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T06:41:30.364749Z","iopub.execute_input":"2025-12-09T06:41:30.365515Z","iopub.status.idle":"2025-12-09T06:41:31.652986Z","shell.execute_reply.started":"2025-12-09T06:41:30.365486Z","shell.execute_reply":"2025-12-09T06:41:31.652323Z"}},"outputs":[{"name":"stdout","text":"Train: (369, 256, 256, 1) (369, 256, 256) N files: 369\nVal  : (80, 256, 256, 1) (80, 256, 256) N files: 80\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1765262491.139221     231 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1765262491.139827     231 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Contoh nama file train[0]: 20190801_0230\nContoh nama file val[0]  : 20190803_1440\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"Train X:\", X_train.shape, \"| dtype:\", X_train.dtype)\nprint(\"Train y:\", y_train.shape, \"| dtype:\", y_train.dtype)\nprint(\"Val   X:\", X_val.shape,   \"| dtype:\", X_val.dtype)\nprint(\"Val   y:\", y_val.shape,   \"| dtype:\", y_val.dtype)\n\nprint(\"N train files:\", len(names_train))\nprint(\"N val files  :\", len(names_val))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T06:41:34.709308Z","iopub.execute_input":"2025-12-09T06:41:34.709905Z","iopub.status.idle":"2025-12-09T06:41:34.715012Z","shell.execute_reply.started":"2025-12-09T06:41:34.709879Z","shell.execute_reply":"2025-12-09T06:41:34.714254Z"}},"outputs":[{"name":"stdout","text":"Train X: (369, 256, 256, 1) | dtype: float32\nTrain y: (369, 256, 256) | dtype: float32\nVal   X: (80, 256, 256, 1) | dtype: float32\nVal   y: (80, 256, 256) | dtype: float32\nN train files: 369\nN val files  : 80\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, Callback\n\n# =========================\n# Opsi: selaraskan bentuk data\n# =========================\n# Pastikan tipe & shape sesuai (model biasanya output (N,H,W,1) dengan sigmoid)\nX_train = X_train.astype(np.float32)\nX_val   = X_val.astype(np.float32)\ny_train = y_train.astype(np.float32)\ny_val   = y_val.astype(np.float32)\n\n# Jika target masih (N,H,W) dan model mengharapkan (N,H,W,1), aktifkan ini:\nif y_train.ndim == 3:\n    y_train = y_train[..., None]\nif y_val.ndim == 3:\n    y_val = y_val[..., None]\n\n# Jika input masih (N,H,W) dan model mengharapkan (N,H,W,1), aktifkan ini juga:\nif X_train.ndim == 3:\n    X_train = X_train[..., None]\nif X_val.ndim == 3:\n    X_val = X_val[..., None]\n\n# =========================\n# Metrik F1 kustom (threshold = 0.5 default)\n# =========================\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1_score', **kwargs):\n        super(F1Score, self).__init__(name=name, **kwargs)\n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # y_pred diasumsikan probabilitas; Precision/Recall akan threshold 0.5\n        self.precision.update_state(y_true, y_pred, sample_weight)\n        self.recall.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        precision = self.precision.result()\n        recall = self.recall.result()\n        return 2.0 * ((precision * recall) / (precision + recall + K.epsilon()))\n\n    def reset_states(self):\n        self.precision.reset_states()\n        self.recall.reset_states()\n\n# =========================\n# Definisi model\n# =========================\n# Asumsikan kamu punya fungsi pembuat model: unet_model() atau attention_unet_model()\nmodel = attention_unet_model()   # atau: model = attention_unet_model()\n# model = unet_model()\n# Pastikan layer terakhir sigmoid dan shape output == y_train.shape[1:]\n\n# =========================\n# Loss functions\n# =========================\ndef focal_loss(alpha=0.25, gamma=2.0):\n    def focal_loss_fixed(y_true, y_pred):\n        # y_pred: probabilitas (0..1)\n        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0 - K.epsilon())\n        pt = tf.where(tf.equal(y_true, 1.0), y_pred, 1.0 - y_pred)\n        alpha_t = tf.where(tf.equal(y_true, 1.0), alpha, 1.0 - alpha)\n        loss = -alpha_t * K.pow(1.0 - pt, gamma) * K.log(pt)\n        return tf.reduce_mean(loss)\n    return focal_loss_fixed\n\ndef weighted_binary_crossentropy(pos_weight=15.0):\n    \"\"\"\n    pos_weight > 1.0 akan memberi penalti lebih besar untuk kelas positif.\n    Bekerja di ruang probabilitas (bukan logits).\n    \"\"\"\n    def loss(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0 - K.epsilon())\n        loss_pos = -pos_weight * y_true * K.log(y_pred)\n        loss_neg = -(1.0 - y_true) * K.log(1.0 - y_pred)\n        loss_all = loss_pos + loss_neg\n        return tf.reduce_mean(loss_all)\n    return loss\n\n# =========================\n# Optimizer & Compile\n# =========================\nlearning_rate = 1e-4\noptimizer = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n\nmodel.compile(\n    optimizer=optimizer,\n    # pilih salah satu:\n    loss=weighted_binary_crossentropy(pos_weight=15.0),\n    # loss=focal_loss(alpha=0.25, gamma=2.0),\n    metrics=[\n        tf.keras.metrics.BinaryAccuracy(name='acc'),\n        tf.keras.metrics.AUC(name='auc_roc', curve='ROC'),\n        tf.keras.metrics.AUC(name='auc_pr',  curve='PR'),\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall'),\n        F1Score(name='f1')\n    ]\n)\n\n# =========================\n# Callbacks\n# =========================\nclass CustomModelCheckpoint(Callback):\n    def __init__(self, filepath, save_freq=100):\n        super(CustomModelCheckpoint, self).__init__()\n        self.filepath = filepath\n        self.save_freq = save_freq\n        \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_freq == 0:\n            filename = self.filepath.format(epoch=epoch + 1)\n            self.model.save(filename)\n            print(f\"\\nModel disimpan di {filename} (Epoch {epoch + 1})\")\n\nclass CustomHistory(Callback):\n    def __init__(self, save_interval=100, save_dir='history'):\n        super(CustomHistory, self).__init__()\n        self.save_interval = save_interval\n        self.save_dir = save_dir\n        os.makedirs(save_dir, exist_ok=True)\n        self.history = {}\n        \n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for key, value in logs.items():\n            self.history.setdefault(key, []).append(value)\n        if (epoch + 1) % self.save_interval == 0:\n            save_path = os.path.join(self.save_dir, f'history_epoch_{epoch + 1}.npy')\n            np.save(save_path, self.history, allow_pickle=True)\n            print(f'History disimpan di {save_path}')\n\n# Direktori kerja & checkpoint\nbase_dir = '/kaggle/working/deteksi_kebakaran'\nmodel_dir = os.path.join(base_dir, 'saved_models')\nhistory_dir = os.path.join(base_dir, 'training_history')\nos.makedirs(model_dir, exist_ok=True)\nos.makedirs(history_dir, exist_ok=True)\n\ncheckpoint_filepath = os.path.join(model_dir, 'model_epoch_{epoch:04d}.keras')\n\nmodel_checkpoint_callback = CustomModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_freq=100\n)\n\ncustom_history_callback = CustomHistory(\n    save_interval=100,\n    save_dir=history_dir\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=10,\n    min_lr=1e-7,\n    verbose=1\n)\n\n# =========================\n# Training\n# =========================\nBATCH_SIZE = 8  # sesuaikan\nEPOCHS = 200\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    callbacks=[model_checkpoint_callback, reduce_lr, custom_history_callback],\n    verbose=1\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# testing the test data","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tqdm import trange\n\n# ======== PARAMETER ========\n# Dataset paths\nPATH_TEST = \"/kaggle/input/datadeteksikebakaran/datasetIR(7)_test.npz\"\n# (Opsional) gunakan validation untuk cari threshold optimal\nPATH_VAL  = \"/kaggle/input/datadeteksikebakaran/datasetIR(7)_val.npz\"\n\n# (Opsional) kalau model TIDAK ada di memori:\nMODEL_PATH = \"/kaggle/input/datadeteksikebakaran/deteksi_kebakaran_2sensorNasa_AttentionUnet_buffer10m_noFilter/saved_models/model_epoch_0200.keras\"\n# MODEL_PATH = None  # set jadi path file .keras kalau mau load dari disk\n\nBATCH_SIZE = 8\n\n# ======== UTIL ========\ndef load_split(npz_path):\n    with np.load(npz_path, allow_pickle=True) as d:\n        X = d[\"input_np\"].astype(np.float32)\n        y = d[\"target_np\"].astype(np.float32)\n        names = d[\"file_names\"].tolist()\n    # Jaga channel last\n    if X.ndim == 3: X = X[..., None]\n    if y.ndim == 3: y = y[..., None]\n    return X, y, names\n\ndef make_dataset(X, y, batch=BATCH_SIZE, training=False):\n    ds = tf.data.Dataset.from_tensor_slices((X, y))\n    if training:\n        ds = ds.shuffle(len(X), reshuffle_each_iteration=True)\n    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n    return ds\n\n# ======== MUAT DATA TEST (dan VAL opsional) ========\nX_test, y_test, names_test = load_split(PATH_TEST)\nds_test = make_dataset(X_test, y_test, training=False)\nprint(\"Test:\", X_test.shape, y_test.shape, \"N files:\", len(names_test))\n\n# (Opsional) untuk threshold optimal\nX_val_opt, y_val_opt = None, None\nif PATH_VAL and os.path.isfile(PATH_VAL):\n    X_val_opt, y_val_opt, _ = load_split(PATH_VAL)\n    ds_val_opt = make_dataset(X_val_opt, y_val_opt, training=False)\n    print(\"Val (for threshold opt):\", X_val_opt.shape, y_val_opt.shape)\n\n# ======== MUAT / PAKAI MODEL ========\nif (MODEL_PATH is not None) and os.path.isfile(MODEL_PATH):\n    # Tidak perlu compile untuk prediksi/evaluasi manual\n    model = load_model(MODEL_PATH, compile=False)   # <— kuncinya di sini\n    print(\"Model loaded (compile=False) from:\", MODEL_PATH)\nelse:\n    assert 'model' in globals(), \"Model tidak ditemukan di memori dan MODEL_PATH tidak diset.\"\n    print(\"Using in-memory model.\")\n\n\n# ======== PREDIKSI PROBABILITAS ========\ny_prob_test = model.predict(ds_test, verbose=1)\n# pastikan shape sama (N,H,W,1)\nif y_prob_test.ndim == 3: y_prob_test = y_prob_test[..., None]\n\n# ======== METRIK BERBASIS AUC (tanpa threshold) ========\n# Flatten ke 1D untuk per-pixel metrics\ny_true_flat = y_test.reshape(-1).astype(np.int32)\ny_prob_flat = y_prob_test.reshape(-1).astype(np.float32)\n\nfrom sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n\nroc_auc = roc_auc_score(y_true_flat, y_prob_flat)\npr_auc  = average_precision_score(y_true_flat, y_prob_flat)  # = PR-AUC\n\nprint(f\"ROC-AUC (test): {roc_auc:.4f}\")\nprint(f\"PR-AUC  (test): {pr_auc:.4f}\")\n\n# ======== BOOTSTRAP 95% CI UNTUK ROC-AUC DAN PR-AUC ========\nfrom numpy.random import default_rng\n\n# Jumlah timestamp di test set (unit bootstrap)\nN_ts = y_test.shape[0]\nprint(\"N test timestamps:\", N_ts)\n\n# Jumlah bootstrap replicates (boleh 200–1000; 500 kompromi bagus)\nB = 200\nrng = default_rng(42)\n\nroc_aucs_bs = []\npr_aucs_bs  = []\n\nfor b in trange(B, desc=\"Bootstrapping ROC/PR\", ncols=80):\n    idx = rng.integers(0, N_ts, size=N_ts)\n\n    y_true_b = y_test[idx].reshape(-1).astype(np.int32)\n    y_prob_b = y_prob_test[idx].reshape(-1).astype(np.float32)\n\n    if len(np.unique(y_true_b)) < 2:\n        continue\n\n    roc_b = roc_auc_score(y_true_b, y_prob_b)\n    pr_b  = average_precision_score(y_true_b, y_prob_b)\n\n    roc_aucs_bs.append(roc_b)\n    pr_aucs_bs.append(pr_b)\n\nroc_aucs_bs = np.array(roc_aucs_bs)\npr_aucs_bs  = np.array(pr_aucs_bs)\n\nprint(f\"Effective bootstrap replicates used: {len(roc_aucs_bs)}\")\n\n# 4) Ambil percentile 2.5% dan 97.5% → CI 95%\nroc_ci = np.percentile(roc_aucs_bs, [2.5, 97.5])\npr_ci  = np.percentile(pr_aucs_bs,  [2.5, 97.5])\n\nprint(f\"ROC-AUC  (test): {roc_auc:.4f}  |  95% CI ≈ [{roc_ci[0]:.4f}, {roc_ci[1]:.4f}]\")\nprint(f\"PR-AUC   (test): {pr_auc:.4f}   |  95% CI ≈ [{pr_ci[0]:.4f}, {pr_ci[1]:.4f}]\")\n\n\n# ======== THRESHOLD: 0.5 dan (opsional) optimal dari validation ========\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n\ndef binarize(prob, thr):\n    return (prob >= thr).astype(np.uint8)\n\ndef metrics_at_threshold(y_true, y_prob, thr):\n    y_pred = binarize(y_prob, thr)\n    P = precision_score(y_true, y_pred, zero_division=0)\n    R = recall_score(y_true, y_pred, zero_division=0)\n    F1 = f1_score(y_true, y_pred, zero_division=0)\n    ACC = accuracy_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    return {\"threshold\": thr, \"precision\": P, \"recall\": R, \"f1\": F1, \"accuracy\": ACC, \"cm\": cm}\n\n# 1) Evaluasi di threshold 0.5\nm05 = metrics_at_threshold(y_true_flat, y_prob_flat, 0.5)\nprint(\"\\n== Metrics @ threshold=0.5 (test) ==\")\nprint(f\"Precision: {m05['precision']:.4f}  Recall: {m05['recall']:.4f}  F1: {m05['f1']:.4f}  Acc: {m05['accuracy']:.4f}\")\nprint(\"Confusion matrix:\\n\", m05['cm'])\n\n# 2) (Opsional) Cari threshold optimal di validation (maks F1), lalu terapkan ke test\nthr_opt = None\nif X_val_opt is not None:\n    y_prob_val = model.predict(ds_val_opt, verbose=0)\n    if y_prob_val.ndim == 3: y_prob_val = y_prob_val[..., None]\n    y_true_val_flat = y_val_opt.reshape(-1).astype(np.int32)\n    y_prob_val_flat = y_prob_val.reshape(-1).astype(np.float32)\n\n    precisions, recalls, thresholds = precision_recall_curve(y_true_val_flat, y_prob_val_flat)\n    # thresholds array panjangnya len(precisions)-1; hitung F1 untuk setiap threshold\n    eps = 1e-9\n    f1s = 2 * precisions[:-1] * recalls[:-1] / (precisions[:-1] + recalls[:-1] + eps)\n    best_idx = np.argmax(f1s)\n    thr_opt = thresholds[best_idx]\n    print(f\"\\n[VAL] Best F1 threshold ≈ {thr_opt:.4f} | P={precisions[best_idx]:.4f} R={recalls[best_idx]:.4f} F1={f1s[best_idx]:.4f}\")\n\n    # Terapkan ke TEST\n    mOPT = metrics_at_threshold(y_true_flat, y_prob_flat, thr_opt)\n    print(\"\\n== Metrics @ threshold=ValBestF1 (applied to test) ==\")\n    print(f\"Threshold: {mOPT['threshold']:.4f}\")\n    print(f\"Precision: {mOPT['precision']:.4f}  Recall: {mOPT['recall']:.4f}  F1: {mOPT['f1']:.4f}  Acc: {mOPT['accuracy']:.4f}\")\n    print(\"Confusion matrix:\\n\", mOPT['cm'])\n\n# ======== OPSIONAL: SIMPAN SKOR PREDIKSI UNTUK ANALISIS LANJUT ========\n# Misal ingin disimpan agar tidak perlu predict ulang untuk plot PR/ROC nanti:\nnp.save(\"/kaggle/working/y_prob_test.npy\", y_prob_test)\nnp.save(\"/kaggle/working/y_true_test.npy\", y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T06:41:45.056785Z","iopub.execute_input":"2025-12-09T06:41:45.057050Z","iopub.status.idle":"2025-12-09T06:55:50.266268Z","shell.execute_reply.started":"2025-12-09T06:41:45.057033Z","shell.execute_reply":"2025-12-09T06:55:50.265499Z"}},"outputs":[{"name":"stdout","text":"Test: (75, 256, 256, 1) (75, 256, 256, 1) N files: 75\nVal (for threshold opt): (80, 256, 256, 1) (80, 256, 256, 1)\nModel loaded (compile=False) from: /kaggle/input/datadeteksikebakaran/deteksi_kebakaran_2sensorNasa_AttentionUnet_buffer10m_noFilter/saved_models/model_epoch_0200.keras\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1765262507.624815     266 service.cc:148] XLA service 0x7fb97c0037a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1765262507.624865     266 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1765262507.624870     266 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1765262507.826086     266 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1765262511.229763     266 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 442ms/step\nROC-AUC (test): 0.9223\nPR-AUC  (test): 0.3601\nN test timestamps: 75\n","output_type":"stream"},{"name":"stderr","text":"Bootstrapping ROC/PR: 100%|███████████████████| 200/200 [13:31<00:00,  4.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Effective bootstrap replicates used: 200\nROC-AUC  (test): 0.9223  |  95% CI ≈ [0.9142, 0.9309]\nPR-AUC   (test): 0.3601   |  95% CI ≈ [0.3055, 0.4139]\n\n== Metrics @ threshold=0.5 (test) ==\nPrecision: 0.2255  Recall: 0.6075  F1: 0.3289  Acc: 0.9620\nConfusion matrix:\n [[4682696  157180]\n [  29567   45757]]\n\n[VAL] Best F1 threshold ≈ 0.8056 | P=0.3871 R=0.3911 F1=0.3891\n\n== Metrics @ threshold=ValBestF1 (applied to test) ==\nThreshold: 0.8056\nPrecision: 0.4243  Recall: 0.3947  F1: 0.4090  Acc: 0.9825\nConfusion matrix:\n [[4799541   40335]\n [  45594   29730]]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Find the optimal threshold based on the objective (precision-first / recall-first / F1-score","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n\ndef sweep_thresholds(y_true_flat, y_prob_flat, num=200):\n    thr_grid = np.linspace(0.0, 1.0, num=num, endpoint=True)\n    rows = []\n    for thr in thr_grid:\n        y_pred = (y_prob_flat >= thr).astype(np.uint8)\n        P = precision_score(y_true_flat, y_pred, zero_division=0)\n        R = recall_score(y_true_flat, y_pred, zero_division=0)\n        F1 = 2*P*R/(P+R+1e-9)\n        ACC = accuracy_score(y_true_flat, y_pred)\n        rows.append((thr, P, R, F1, ACC))\n    return np.array(rows)  # cols: thr, P, R, F1, ACC\n\ngrid = sweep_thresholds(y_true_flat, y_prob_flat, num=401)\n\n# contoh pemilihan:\n# a) threshold dengan F1 maksimum\nthr_f1 = grid[np.argmax(grid[:,3]), 0]\n\n# b) threshold minimal precision (mis. ≥ 0.60) dengan recall tertinggi\nmask = grid[:,1] >= 0.60\nthr_p60 = grid[mask][np.argmax(grid[mask][:,2]), 0] if np.any(mask) else None\n\n# c) threshold minimal recall (mis. ≥ 0.60) dengan precision tertinggi\nmask = grid[:,2] >= 0.60\nthr_r60 = grid[mask][np.argmax(grid[mask][:,1]), 0] if np.any(mask) else None\n\nprint(\"Best F1 thr:\", thr_f1)\nprint(\"Precision≥0.60 thr:\", thr_p60)\nprint(\"Recall≥0.60 thr:\", thr_r60)\n\ndef report_at_thr(y_true, y_prob, thr, title):\n    y_pred = (y_prob >= thr).astype(np.uint8)\n    P = precision_score(y_true, y_pred, zero_division=0)\n    R = recall_score(y_true, y_pred, zero_division=0)\n    F1 = f1_score(y_true, y_pred, zero_division=0)\n    ACC = accuracy_score(y_true, y_pred)\n    CM = confusion_matrix(y_true, y_pred)\n    print(f\"\\n== {title} ==\")\n    print(f\"thr={thr:.4f} | P={P:.4f} R={R:.4f} F1={F1:.4f} ACC={ACC:.4f}\")\n    print(\"Confusion matrix:\\n\", CM)\n\nreport_at_thr(y_true_flat, y_prob_flat, thr_f1, \"Test @ Best F1(thr grid)\")\nif thr_p60 is not None: report_at_thr(y_true_flat, y_prob_flat, thr_p60, \"Test @ Precision≥0.60\")\nif thr_r60 is not None: report_at_thr(y_true_flat, y_prob_flat, thr_r60, \"Test @ Recall≥0.60\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport geopandas as gpd\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom matplotlib.colors import ListedColormap\nfrom shapely.geometry import box\nimport scipy.ndimage as ndi\nfrom scipy.spatial import cKDTree\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, average_precision_score, confusion_matrix\n)\n\n# ========= PATHS =========\nPATH_TEST_NPZ = \"/kaggle/input/datadeteksikebakaran/datasetIR(7)_test.npz\"\nMODEL_PATH = \"/kaggle/input/datadeteksikebakaran/deteksi_kebakaran_2sensorNasa_AttentionUnet/saved_models/model_epoch_0200.keras\"\n\n# ========= OUTPUT (SAVE FIGS) =========\nSAVE_DIR   = \"/kaggle/working/deteksi_kebakaran\"  # <-- folder simpan gambar\nSAVE_FIGS  = True                                 # simpan gambar?\nSHOW_FIGS  = False                                # tampilkan jendela gambar?\nSAVE_DPI   = 300                                  # resolusi simpan\n\n# ========= PARAMS =========\nMIN_SIZE = 9\nTHR = 0.8056\nMATCH_RADIUS = 8.0\nN_SAMPLES_TO_PLOT = 75\n\n# --- Opsi pemilihan & pengurutan plot ---\nSELECT_TIMESTAMPS = ['20190907_1510','20191029_1450','20190907_0250','20190907_0530']  # contoh: ['20190907_0620','20191006_0720','20190803_1220']\nPLOT_TOP_K = N_SAMPLES_TO_PLOT\n\n# ========= CUSTOM OBJECTS =========\n@tf.keras.utils.register_keras_serializable()\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1_score', **kwargs):\n        super(F1Score, self).__init__(name=name, **kwargs)\n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.precision.update_state(y_true, y_pred, sample_weight)\n        self.recall.update_state(y_true, y_pred, sample_weight)\n    def result(self):\n        p = self.precision.result()\n        r = self.recall.result()\n        return 2.0 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n    def reset_states(self):\n        super().reset_states()\n        self.precision.reset_states()\n        self.recall.reset_states()\n\n@tf.keras.utils.register_keras_serializable()\ndef weighted_binary_crossentropy(pos_weight=15.0):\n    def loss(y_true, y_pred):\n        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n        weights = y_true * pos_weight + (1 - y_true) * 1.0\n        return tf.reduce_mean(weights * bce)\n    return loss\n\ndef remove_small_blobs(mask, min_size=3):\n    lab, n = ndi.label(mask)\n    if n == 0:\n        return mask\n    counts = np.bincount(lab.ravel())\n    keep = np.isin(lab, np.where(counts >= min_size)[0])\n    return (keep & (lab > 0)).astype(np.uint8)\n\nMIN_SIZE_OBJ = max(3, MIN_SIZE)\n\ndef label_and_centroids(mask, min_size=MIN_SIZE_OBJ):\n    structure = np.ones((3,3), dtype=np.uint8)  # 8-connectivity\n    lab, n = ndi.label(mask.astype(np.uint8), structure=structure)\n    if n == 0:\n        return np.zeros_like(mask, dtype=np.int32), np.empty((0,2), dtype=float)\n    sizes = np.bincount(lab.ravel())\n    keep = np.isin(lab, np.where(sizes >= min_size)[0])\n    lab = lab * keep\n    lab, _ = ndi.label(lab > 0, structure=structure)\n    if lab.max() == 0:\n        return lab.astype(np.int32), np.empty((0,2), dtype=float)\n    cents = ndi.center_of_mass(np.ones_like(mask, dtype=np.uint8), labels=lab, index=range(1, lab.max()+1))\n    return lab.astype(np.int32), np.array(cents, dtype=float)  # (K,2) -> (y,x)\n\ndef greedy_match_by_radius(cents_gt, cents_pred, radius=MATCH_RADIUS):\n    if len(cents_gt) == 0 and len(cents_pred) == 0:\n        return [], [], []\n    if len(cents_gt) == 0:\n        return [], [], list(range(len(cents_pred)))\n    if len(cents_pred) == 0:\n        return [], list(range(len(cents_gt))), []\n    tree = cKDTree(cents_pred)\n    dists, idxs = tree.query(cents_gt, k=1, distance_upper_bound=radius)\n    matched, used_pred = [], set()\n    for i_gt, (d, j_pred) in enumerate(zip(dists, idxs)):\n        if np.isfinite(d) and j_pred < len(cents_pred) and j_pred not in used_pred:\n            matched.append((i_gt, j_pred)); used_pred.add(j_pred)\n    matched_gt = {i for i,_ in matched}\n    matched_pr = {j for _,j in matched}\n    un_gt = [i for i in range(len(cents_gt))  if i not in matched_gt]\n    un_pr = [j for j in range(len(cents_pred)) if j not in matched_pr]\n    return matched, un_gt, un_pr\n\ndef object_level_counts(gt_mask, pred_mask, radius=MATCH_RADIUS, min_size=MIN_SIZE_OBJ):\n    _, cg = label_and_centroids(gt_mask,  min_size=min_size)\n    _, cp = label_and_centroids(pred_mask, min_size=min_size)\n    matched, un_gt, un_pr = greedy_match_by_radius(cg, cp, radius=radius)\n    TP_obj = len(matched); FN_obj = len(un_gt); FP_obj = len(un_pr)\n    return TP_obj, FP_obj, FN_obj\n\n# ========= LOAD MODEL & DATA =========\nmodel = tf.keras.models.load_model(\n    MODEL_PATH,\n    custom_objects={\n        'F1Score': F1Score,\n        'weighted_binary_crossentropy': weighted_binary_crossentropy,\n        'loss': weighted_binary_crossentropy()\n    }\n)\nprint(\"Loaded model from:\", MODEL_PATH)\n\nwith np.load(PATH_TEST_NPZ, allow_pickle=True) as d:\n    X_test = d[\"input_np\"].astype(np.float32)\n    y_test = d[\"target_np\"].astype(np.float32)\n    names_test = d[\"file_names\"].tolist()\n\nif X_test.ndim == 3: X_test = X_test[..., None]\nif y_test.ndim == 3: y_test = y_test[..., None]\n\nprint(\"Test shapes:\", X_test.shape, y_test.shape, \"| N files:\", len(names_test))\n\n# ========= GEO =========\nshapefile_path = '/kaggle/input/datadeteksikebakaran/gadm41_IDN_1.shp'\nboundaries = gpd.read_file(shapefile_path)\n\nlat_lower = -3.650602881343665\nlat_upper =  1.469398964128776\nlon_lower = 110.73089588122669\nlon_upper = 115.85088234776212\nextent = [lon_lower, lon_upper, lat_lower, lat_upper]\n\nroi = gpd.GeoDataFrame(geometry=[box(lon_lower, lat_lower, lon_upper, lat_upper)], crs='EPSG:4326')\nprovinsi_kalteng_roi = gpd.overlay(boundaries, roi, how='intersection')\n\nbinary_cmap = ListedColormap([[0, 0, 0, 0.0], [1, 0, 0, 0.85]])\n\n# ========= PLOTTING (4 panel) =========\ndef plot_sample_with_boundary(input_image, pred_mask, gt_mask, boundaries, file_name,\n                              pc, oe, ce, f1_obj, flip=True, scatter_max=5000,\n                              save_dir=None, save_basename=None, save_dpi=300, show=False):\n    H, W = input_image.shape[:2]\n    img2d = input_image.squeeze()\n\n    lon = np.linspace(lon_lower, lon_upper, W)\n    lat = np.linspace(lat_lower, lat_upper, H)\n    lon_mesh, lat_mesh = np.meshgrid(lon, lat)\n\n    fig, axs = plt.subplots(1, 4, figsize=(24, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n\n    # Panel 1: Input\n    base = np.flipud(img2d) if flip else img2d\n    im0 = axs[0].pcolormesh(lon_mesh, lat_mesh, base, cmap='RdYlBu_r', transform=ccrs.PlateCarree())\n    boundaries.boundary.plot(ax=axs[0], edgecolor='black')\n    axs[0].set_title(f'Input Image: {file_name}')\n    axs[0].set_extent(extent, crs=ccrs.PlateCarree())\n    axs[0].coastlines(resolution='10m', color='black', linewidth=1)\n    axs[0].add_feature(cfeature.BORDERS, linestyle=':', linewidth=1, edgecolor='black')\n    fig.colorbar(im0, ax=axs[0], orientation='vertical', fraction=0.046, pad=0.04)\n\n    def idx_to_lonlat_southup(mask):\n        yy, xx = np.where(mask > 0)\n        if len(yy) == 0:\n            return np.array([]), np.array([])\n        Hh, Ww = mask.shape\n        lon_arr = lon_lower + (xx + 0.5) * (lon_upper - lon_lower) / Ww\n        lat_arr = lat_lower + (yy + 0.5) * (lat_upper - lat_lower) / Hh\n        if len(lon_arr) > scatter_max:\n            sel = np.random.choice(len(lon_arr), scatter_max, replace=False)\n            lon_arr, lat_arr = lon_arr[sel], lat_arr[sel]\n        return lon_arr, lat_arr\n\n    # Panel 2: Prediction\n    pred_show = np.flipud(pred_mask) if flip else pred_mask\n    if np.count_nonzero(pred_show) > 0:\n        axs[1].imshow(pred_show, cmap=binary_cmap, extent=extent, origin='lower',\n                      transform=ccrs.PlateCarree(), alpha=0.9, interpolation='nearest', zorder=2)\n        axs[1].contour(lon_mesh, lat_mesh, pred_show, levels=[0.5], colors='red',\n                       linewidths=0.6, transform=ccrs.PlateCarree(), zorder=3)\n        lon_p, lat_p = idx_to_lonlat_southup(pred_show)\n        if lon_p.size:\n            axs[1].scatter(lon_p, lat_p, s=6, c='red', transform=ccrs.PlateCarree(),\n                           edgecolors='none', linewidths=0, zorder=4, label='Predicted Fire')\n    boundaries.boundary.plot(ax=axs[1], edgecolor='black', zorder=5)\n    axs[1].set_title('Predicted Mask')\n    axs[1].set_extent(extent, crs=ccrs.PlateCarree())\n    axs[1].coastlines(resolution='10m', color='black', linewidth=1)\n    axs[1].add_feature(cfeature.BORDERS, linestyle=':', linewidth=1, edgecolor='black')\n    axs[1].text(0.5, -0.32,\n                f'PC: {pc:.2f}%\\nOE: {oe:.2f}%\\nCE: {ce:.2f}%\\nF1(obj): {f1_obj:.2f}%',\n                ha='center', va='center', transform=axs[1].transAxes, fontsize=10,\n                bbox=dict(facecolor='white', alpha=0.9))\n    axs[1].legend(loc='upper left')\n\n    # Panel 3: Ground Truth\n    gt_show = np.flipud(gt_mask) if flip else gt_mask\n    if np.count_nonzero(gt_show) > 0:\n        axs[2].imshow(gt_show, cmap=binary_cmap, extent=extent, origin='lower',\n                      transform=ccrs.PlateCarree(), alpha=0.9, interpolation='nearest', zorder=2)\n        axs[2].contour(lon_mesh, lat_mesh, gt_show, levels=[0.5], colors='red',\n                       linewidths=0.6, transform=ccrs.PlateCarree(), zorder=3)\n        lon_g, lat_g = idx_to_lonlat_southup(gt_show)\n        if lon_g.size:\n            axs[2].scatter(lon_g, lat_g, s=6, c='red', transform=ccrs.PlateCarree(),\n                           edgecolors='none', linewidths=0, zorder=4, label='Ground Truth Fire')\n    boundaries.boundary.plot(ax=axs[2], edgecolor='black', zorder=5)\n    axs[2].set_title('Ground Truth Mask')\n    axs[2].set_extent(extent, crs=ccrs.PlateCarree())\n    axs[2].coastlines(resolution='10m', color='black', linewidth=1)\n    axs[2].add_feature(cfeature.BORDERS, linestyle=':', linewidth=1, edgecolor='black')\n    axs[2].legend(loc='upper left')\n\n    # Panel 4: Overlay TP/FP/FN\n    overlay = np.zeros_like(pred_show, dtype=np.uint8)\n    TP = (pred_show == 1) & (gt_show == 1)\n    FP = (pred_show == 1) & (gt_show == 0)\n    FN = (pred_show == 0) & (gt_show == 1)\n    overlay[TP] = 1  # green\n    overlay[FP] = 2  # red\n    overlay[FN] = 3  # orange\n\n    overlay_cmap = ListedColormap([\n        (0, 0, 0, 0.0),        # none\n        (0.0, 0.6, 0.0, 0.85), # TP\n        (0.9, 0.0, 0.0, 0.85), # FP\n        (1.0, 0.55, 0.0, 0.85) # FN\n    ])\n\n    axs[3].imshow(overlay, cmap=overlay_cmap, extent=extent, origin='lower',\n                  transform=ccrs.PlateCarree(), interpolation='nearest', zorder=2)\n    boundaries.boundary.plot(ax=axs[3], edgecolor='black', zorder=5)\n    axs[3].set_title('Overlay: TP/FP/FN')\n    axs[3].set_extent(extent, crs=ccrs.PlateCarree())\n    axs[3].coastlines(resolution='10m', color='black', linewidth=1)\n    axs[3].add_feature(cfeature.BORDERS, linestyle=':', linewidth=1, edgecolor='black')\n    legend_handles = [\n        mpatches.Patch(color=(0.0, 0.6, 0.0, 0.85), label='TP'),\n        mpatches.Patch(color=(0.9, 0.0, 0.0, 0.85), label='FP'),\n        mpatches.Patch(color=(1.0, 0.55, 0.0, 0.85), label='FN'),\n    ]\n    axs[3].legend(handles=legend_handles, loc='upper left')\n\n    plt.tight_layout()\n\n    # ==== SAVE ====\n    if save_dir is not None:\n        os.makedirs(save_dir, exist_ok=True)\n        if not save_basename:\n            save_basename = str(file_name)\n        out_path = os.path.join(save_dir, f\"{save_basename}.png\")\n        fig.savefig(out_path, dpi=save_dpi, bbox_inches='tight')\n        print(f\"[SAVED] {out_path}\")\n\n    # show/close\n    if show:\n        plt.show()\n    else:\n        plt.close(fig)\n\n# ========= PASS 1: hitung metrik per-sample =========\ndef _key(n):\n    return os.path.splitext(os.path.basename(str(n)))[0]\n\nname_keys = [_key(n) for n in names_test]\n\nTP_OBJ_TOT = FP_OBJ_TOT = FN_OBJ_TOT = 0\nper_sample = []\n\nfor i in range(len(X_test)):\n    x_np = X_test[i]\n    y_np = y_test[i]\n\n    y_prob = model.predict(x_np[None, ...], verbose=0)\n    y_pred = (y_prob[0, ..., 0] >= THR).astype(np.uint8)\n    y_pred = remove_small_blobs(y_pred, min_size=MIN_SIZE)\n    y_true = (y_np[..., 0] >= 0.5).astype(np.uint8)\n\n    TPo, FPo, FNo = object_level_counts(y_true, y_pred, radius=MATCH_RADIUS, min_size=MIN_SIZE_OBJ)\n    TP_OBJ_TOT += TPo; FP_OBJ_TOT += FPo; FN_OBJ_TOT += FNo\n\n    prec_obj = TPo / (TPo + FPo) if (TPo + FPo) > 0 else 0.0\n    rec_obj  = TPo / (TPo + FNo) if (TPo + FNo) > 0 else 0.0\n    ce_obj = (1.0 - prec_obj) * 100.0\n    oe_obj = (1.0 - rec_obj)  * 100.0\n    pc_obj = (TPo) / (TPo + FPo + FNo) * 100.0 if (TPo + FPo + FNo) > 0 else 0.0\n    f1_obj = (2*prec_obj*rec_obj/(prec_obj+rec_obj) if (prec_obj+rec_obj)>0 else 0.0) * 100.0\n\n    per_sample.append({\n        'i': i,\n        'name': name_keys[i],\n        'TP': TPo, 'FP': FPo, 'FN': FNo,\n        'CE': ce_obj, 'OE': oe_obj, 'PC': pc_obj, 'F1': f1_obj\n    })\n\n# ===== Ringkasan mikro (objek) =====\nden_ce = TP_OBJ_TOT + FP_OBJ_TOT\nden_oe = TP_OBJ_TOT + FN_OBJ_TOT\nCE_obj_micro = 100.0 * FP_OBJ_TOT / den_ce if den_ce > 0 else 0.0\nOE_obj_micro = 100.0 * FN_OBJ_TOT / den_oe if den_oe > 0 else 0.0\nprec_obj_micro = TP_OBJ_TOT / (TP_OBJ_TOT + FP_OBJ_TOT) if (TP_OBJ_TOT + FP_OBJ_TOT) > 0 else 0.0\nrec_obj_micro  = TP_OBJ_TOT / (TP_OBJ_TOT + FN_OBJ_TOT) if (TP_OBJ_TOT + FN_OBJ_TOT) > 0 else 0.0\nF1_obj_micro   = 2*prec_obj_micro*rec_obj_micro/(prec_obj_micro+rec_obj_micro) if (prec_obj_micro+rec_obj_micro)>0 else 0.0\nPC_obj_micro   = 100.0 * TP_OBJ_TOT / (TP_OBJ_TOT + FP_OBJ_TOT + FN_OBJ_TOT) if (TP_OBJ_TOT + FP_OBJ_TOT + FN_OBJ_TOT) > 0 else 0.0\n\nprint(\"\\n=== SUMMARY (object-level, micro-average) ===\")\nprint(f\"TP_obj={TP_OBJ_TOT}  FP_obj={FP_OBJ_TOT}  FN_obj={FN_OBJ_TOT}\")\nprint(f\"Commission error (Obj): {CE_obj_micro:.2f}%\")\nprint(f\"Omission error (Obj) : {OE_obj_micro:.2f}%\")\nprint(f\"F1 (object)         : {F1_obj_micro*100:.2f}%\")\nprint(f\"Object correctness  : {PC_obj_micro:.2f}%\")\n\n# ========= PILIH & URUTKAN UNTUK DIPLOT =========\nif SELECT_TIMESTAMPS:\n    selected_set = set(SELECT_TIMESTAMPS)\n    found_names = {d['name'] for d in per_sample}\n    missing = [ts for ts in SELECT_TIMESTAMPS if ts not in found_names]\n    if missing:\n        print(\"[WARNING] Timestamp tidak ditemukan di test split:\", missing)\n    plot_list = [d for d in per_sample if d['name'] in selected_set]\nelse:\n    plot_list = per_sample[:]\n\nplot_list.sort(key=lambda d: (d['CE'], d['OE']))\nif not SELECT_TIMESTAMPS:\n    plot_list = plot_list[:PLOT_TOP_K]\n\n# ========= PLOT & SAVE SESUAI URUTAN =========\nif SAVE_FIGS:\n    os.makedirs(SAVE_DIR, exist_ok=True)\n\nfor rank, d in enumerate(plot_list, start=1):\n    i = d['i']\n    x_np = X_test[i]\n    y_np = y_test[i]\n    # recompute untuk kepastian visual\n    y_prob = model.predict(x_np[None, ...], verbose=0)\n    y_pred = (y_prob[0, ..., 0] >= THR).astype(np.uint8)\n    y_pred = remove_small_blobs(y_pred, min_size=MIN_SIZE)\n    y_true = (y_np[..., 0] >= 0.5).astype(np.uint8)\n\n    save_basename = f\"{rank:03d}_{d['name']}_CE{d['CE']:.1f}_OE{d['OE']:.1f}\"\n    print(f\"[PLOT] {save_basename}\")\n\n    plot_sample_with_boundary(\n        x_np.squeeze(), y_pred, y_true, provinsi_kalteng_roi, d['name'],\n        pc=d['PC'], oe=d['OE'], ce=d['CE'], f1_obj=d['F1'],\n        flip=True, scatter_max=4000,\n        save_dir=(SAVE_DIR if SAVE_FIGS else None),\n        save_basename=save_basename,\n        save_dpi=SAVE_DPI,\n        show=SHOW_FIGS\n    )\n\n# ========= PIXEL-LEVEL (opsional) =========\ny_prob_test = model.predict(X_test, verbose=1)\ny_true_flat = y_test.reshape(-1).astype(np.int32)\ny_prob_flat = y_prob_test.reshape(-1).astype(np.float32)\n\nroc_auc = roc_auc_score(y_true_flat, y_prob_flat)\npr_auc  = average_precision_score(y_true_flat, y_prob_flat)\nprint(f\"\\nROC-AUC (test): {roc_auc:.4f}\")\nprint(f\"PR-AUC  (test): {pr_auc:.4f}\")\n\ny_pred_flat = (y_prob_flat >= THR).astype(np.uint8)\nP = precision_score(y_true_flat, y_pred_flat, zero_division=0)\nR = recall_score(y_true_flat, y_pred_flat, zero_division=0)\nF1 = f1_score(y_true_flat, y_pred_flat, zero_division=0)\nACC = accuracy_score(y_true_flat, y_pred_flat)\nCM = confusion_matrix(y_true_flat, y_pred_flat)\n\nprint(f\"\\n== Pixel-level metrics @ threshold={THR:.4f} ==\")\nprint(f\"Precision: {P:.4f}  Recall: {R:.4f}  F1: {F1:.4f}  Accuracy: {ACC:.4f}\")\nprint(\"Confusion matrix:\\n\", CM)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}